{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not use other NN (or similar) packages for implementation\n",
    "\n",
    "You should implement the forward and backward/gradient computation by yourself. Your implementation should <b>NOT</b> be a wrapper of some existing packages (such as tensorflow, pytorch etc). For example the following code:\n",
    "\n",
    "    import some_lib \n",
    "    def compute_gradients(x, y):\n",
    "        return som_lib.compute_gradients(x,y)\n",
    "        \n",
    "will get \"0\" point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "When it comes to matrix/vector computation, you must use the package \"numpy\". For example, you may need to compute:\n",
    "\n",
    "$$C_{j, k} = \\sum_i A_{i, j}\\times B_{i, k}$$.\n",
    "\n",
    "Observing that this is a matrix multiplication $C = A^TB$, you can compute it by:\n",
    "\n",
    "    import numpy\n",
    "    C = numpy.dot(A.T, B)\n",
    "    \n",
    "Do not implement basic matrix/vector computation by loops, for example\n",
    "    \n",
    "    \n",
    "    for j = 1 ...\n",
    "        for k = 1 ...\n",
    "            for i = 1 ...\n",
    "                C[j, k] += A[i, j]*B[i, k]\n",
    "                \n",
    "The loop implementation in python can be 1000 time slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your implementation\n",
    "\n",
    "You can compare the result from runing your implementation to that from an existing NN package to check the correctness of your code. The following code build a network using keras and train it with the digits data. You can compare the loss calculated and the values of the parameters between your code and the keras model. (Both code should use the same initial values and minibatch for the comparison to be meaningful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "def make_model(config):\n",
    "    layers = config['layers']\n",
    "    m = Sequential()\n",
    "    m.add(Dense(layers[0], input_dim=config['input_dim'], activation='relu'))\n",
    "    for n in layers[1:]:\n",
    "        m.add(Dense(n, activation='relu'))\n",
    "    m.add(Dense(1, activation='sigmoid'))\n",
    "    sgd = SGD(lr=1e-3)\n",
    "    m.compile(loss='mse', optimizer=sgd)\n",
    "    return m\n",
    "\n",
    "\n",
    "m = make_model({'input_dim':28*28, 'layers':[20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(X, y, i, n, ny):\n",
    "    ixs = np.nonzero(y == i)[0]\n",
    "    Xn = X[ixs[np.random.permutation(len(ixs))[:n]]]\n",
    "    yn = ny*np.ones((n,))\n",
    "    return Xn, yn\n",
    "\n",
    "X0, y0 = select_data(x_train, y_train, 2, 1000, 0)\n",
    "X1, y1 = select_data(x_train, y_train, 6, 1000, 1)\n",
    "X = np.concatenate([X0, X1], axis=0)\n",
    "y = np.concatenate([y0, y1], axis=0)\n",
    "\n",
    "# shuffle data\n",
    "ixs = np.random.permutation(len(y))\n",
    "X = X[ixs].reshape((len(y), -1))\n",
    "y = y[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 0s 70us/step - loss: 0.5040\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.5035\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.5035\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.5035\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 55us/step - loss: 0.5033\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.5020\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.5020\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.5015\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.5015\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 0s 55us/step - loss: 0.5015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2acf9089748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TensorBoard(log_dir='./logs')\n",
    "m.fit(X, y, batch_size=32, epochs=10, shuffle=False, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
